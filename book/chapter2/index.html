
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A live review and exploration of Spatial Omics literature and data.">
      
      
      
        <link rel="canonical" href="https://marta-seq.github.io/solr/book/chapter2/">
      
      
        <link rel="prev" href="../chapter1/">
      
      
        <link rel="next" href="../chapter3/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>Chapter 2 - Spatial Omics Live Review</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="light-blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#analytical-frameworks-for-spatial-omics-data" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Spatial Omics Live Review" class="md-header__button md-logo" aria-label="Spatial Omics Live Review" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Spatial Omics Live Review
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Chapter 2
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="light-blue"  aria-hidden="true"  type="radio" name="__palette" id="__palette_0">
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  
  Book

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../datasets/" class="md-tabs__link">
        
  
  
    
  
  Spatial Omics Datasets

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../methods/" class="md-tabs__link">
        
  
  
    
  
  Spatial Omics Methods

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../applications/" class="md-tabs__link">
        
  
  
    
  
  Spatial Omics Applications

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Spatial Omics Live Review" class="md-nav__button md-logo" aria-label="Spatial Omics Live Review" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Spatial Omics Live Review
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Book
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Book
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Chapter 2
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Chapter 2
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#data-preprocessing" class="md-nav__link">
    <span class="md-ellipsis">
      Data preprocessing
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Data preprocessing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#spatial-proteomics" class="md-nav__link">
    <span class="md-ellipsis">
      Spatial proteomics
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spatial-transcriptomics" class="md-nav__link">
    <span class="md-ellipsis">
      Spatial transcriptomics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cell-segmentation" class="md-nav__link">
    <span class="md-ellipsis">
      Cell segmentation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Cell segmentation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#spatial-proteomics_1" class="md-nav__link">
    <span class="md-ellipsis">
      Spatial proteomics
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spatial-transcriptomics_1" class="md-nav__link">
    <span class="md-ellipsis">
      Spatial transcriptomics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cell-phenotyping" class="md-nav__link">
    <span class="md-ellipsis">
      Cell phenotyping
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Cell phenotyping">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#spatial-proteomics_2" class="md-nav__link">
    <span class="md-ellipsis">
      Spatial proteomics
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spatial-transcriptomics_2" class="md-nav__link">
    <span class="md-ellipsis">
      Spatial transcriptomics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cellular-neighbourhood-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Cellular neighbourhood analysis
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spatial-domains" class="md-nav__link">
    <span class="md-ellipsis">
      Spatial domains
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spatially-variable-genes" class="md-nav__link">
    <span class="md-ellipsis">
      Spatially Variable genes
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#functional-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Functional analysis
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-to-distinguish-between-sample-conditions" class="md-nav__link">
    <span class="md-ellipsis">
      How to distinguish between sample conditions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="How to distinguish between sample conditions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#summary-statistics" class="md-nav__link">
    <span class="md-ellipsis">
      Summary statistics
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#matrix-factorization-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Matrix factorization methods
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#machine-learning-and-deep-learning-approaches" class="md-nav__link">
    <span class="md-ellipsis">
      Machine Learning and Deep Learning approaches
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#frameworks-and-tools-for-spatial-omics-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      Frameworks and tools for spatial omics analysis
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#closing-remarks" class="md-nav__link">
    <span class="md-ellipsis">
      Closing remarks
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chapter 3
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../references.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    References
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../datasets/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Spatial Omics Datasets
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../methods/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Spatial Omics Methods
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../applications/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Spatial Omics Applications
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="analytical-frameworks-for-spatial-omics-data">Analytical Frameworks for Spatial Omics Data</h1>
<p>The increasing availability of high-resolution spatial omics
data---particularly at subcellular resolution---brings new computational
challenges, including those related to the spatial dimension, increased
data complexity, and multiplexing. This chapter focuses on the analysis
of single-molecule spatial transcriptomics and proteomics, where each
detected molecule is mapped with precise spatial coordinates. While the
field is rapidly evolving, with a growing number of specialized tools
and packages emerging at a fast pace, this work will centre on the core
analytical pipeline common to most imaging-based platforms. Methods
specific to certain technologies---such as deconvolution approaches
designed for lower-resolution platforms like 10x Visium---or complex
multimodal integration strategies with single-cell data will not be
covered here.</p>
<h2 id="data-preprocessing">Data preprocessing</h2>
<p>Both spatial proteomics and spatial transcriptomics require dedicated
preprocessing steps to mitigate technical noise and artifacts that may
obscure true biological signals. These preprocessing strategies differ
significantly, reflecting the distinct nature of the underlying
technologies.</p>
<h3 id="spatial-proteomics">Spatial proteomics</h3>
<p>For spatial proteomics noise sources can vary based on the antibodies,
detection channels, and tissue types used, and may manifest as artifacts
such as hot pixels, shot noise, background noise and channel
crosstalk^1--3^ and may also exhibit low signal-to-noise ratios^4^.</p>
<p>Channel crosstalk, where signals from one channel interfere with
adjacent channels, can be mitigated through well-designed antibody
panels^4^ or correction methods like CATALYST^3^, which uses
pre-acquisition compensation matrices, as well as post-processing
techniques^2,5^.</p>
<p>Beyond crosstalk, other sources of noise---such as hot pixels,
background signal, and shot noise---require distinct computational
strategies. Some studies have employed adjacent approaches, including
those implemented in Steinbock^6^ and MAUI (MBI analysis interface)^2^,
while others have developed "homebrew" methods based on traditional
image filtering techniques^5,7,8^. However, these methods are often
insufficient for fully addressing complex noise patterns.</p>
<p>Tools like Ilastik^9^ provide supervised pixel classification to
distinguish background noise from true signal on a per-marker
basis^6,9,10^. Although this approach requires extensive manual
annotation, it is currently considered state-of-the-art, as it
effectively removes background noise and improves signal normalization
and batch effect reduction across samples^7^. More recently,
IMC-Denoise^11^ has been introduced as a two-step pipeline combining
traditional algorithms with a self-supervised deep learning model based
on Noise2Void^12^.</p>
<p>Notably, this thesis contributes to this specific challenge, as
discussed in Chapter <a href="#ch:penguin">[ch:penguin]</a>{reference-type="ref"
reference="ch:penguin"}.</p>
<h3 id="spatial-transcriptomics">Spatial transcriptomics</h3>
<p>For spatial transcriptomics, preprocessing aims to reduce technical
noise introduced during tissue handling, permeabilization, probe
hybridization, and sequencing. One of the first steps involves removing
low-quality spatial barcodes or transcript reads, which can arise from
ambient RNA contamination, incomplete permeabilization, or sequencing
artifacts. In some commercial platforms (such as Xenium), quality scores
or confidence values are assigned to individual transcripts; Transcripts
below a defined threshold can be excluded to avoid false positives. To
further refine the dataset, transcripts detected at extremely low
frequency across the tissue may be removed.</p>
<h2 id="cell-segmentation">Cell segmentation</h2>
<p>A central challenge in spatial omics is the accurate assignment of
molecular measurements---transcripts or proteins---to individual cells.
This process, known as cell segmentation, is essential for translating
spatial data into single-cell level insights and directly influences
downstream biological interpretation.</p>
<h3 id="spatial-proteomics_1">Spatial proteomics</h3>
<p>In spatial proteomics, cell segmentation is typically performed using
the imaging data generated during acquisition. These multiplexed images
often include nuclear stains to identify nuclei and membrane markers to
delineate cell boundaries. These signals are combined into RGB or
multi-channel images and processed using image analysis pipelines.</p>
<p>Traditional image segmentation approaches, such as thresholding, edge
detection, and the watershed algorithm, are commonly employed. These
methods are implemented in established tools like CellProfiler^13,14^
and ImageJ/Fiji^15^, which allow customization of segmentation pipelines
using scripting interfaces. In recent years, DL models have gained
prominence due to their improved accuracy, generalizability, and
community availability^16^. Notably, Mesmer, part of the DeepCell
framework, DL-based model specifically trained on spatial proteomics
datasets, leveraging TissueNet, a large annotated dataset^17^. Another
widely adopted method is Cellpose, a generalist DL segmentation tool
that predicts vector flows to delineate cell boundaries instead of
relying on direct pixel-wise classification. Though originally trained
on a broad array of microscopy images, Cellpose also offers specialist
models, including those fine-tuned on TissueNet subsets to enhance
performance on spatial proteomics images^18,19^.</p>
<p>Segmentation strategies in spatial proteomics range from nucleus-based
expansion methods, which approximate cell outlines from DAPI staining,
to full-cell segmentation techniques that incorporate both nuclear and
membrane markers. A growing number of domain-specific models continue to
emerge, each tailored to address the distinct noise profiles, spatial
resolution, and multiplexing characteristics of spatial proteomics
data^20--24^.</p>
<p>This thesis also contributes to this domain, as discussed in
Chapter <a href="#ch:Cellcytolego">[ch:Cellcytolego]</a>{reference-type="ref"
reference="ch:Cellcytolego"}.</p>
<h3 id="spatial-transcriptomics_1">Spatial transcriptomics</h3>
<p>The landscape of spatial transcriptomics segmentation is more varied
than in proteomics. In subcellular-resolution platforms such as Xenium
and CosMx, segmentation is often performed using accompanying IF images,
which typically include nuclear (e.g., DAPI) and membrane markers. These
images enable the identification of cell boundaries, which are then used
to assign transcripts to individual cells by overlaying segmentation
masks with transcript positions.</p>
<p>Alternatively, several methods bypass image-based segmentation
altogether. Since transcripts are detected directly as spatial
coordinates, these approaches aim to infer cell boundaries based solely
on the spatial distribution and density of transcripts, reducing
dependency on auxiliary images^25--33^.</p>
<p>A prominent example is Baysor^25^, a general probabilistic framework
implemented in Julia. Based on [MRF]{acronym-label="MRF"
acronym-form="singular+short"}, Baysor models cells by jointly
considering spatial proximity and transcriptional similarity. It can
incorporate prior segmentations, assigning confidence scores to them, or
operate de novo using only transcript data. Baysor functions in both 2D
and 3D, optimizing the likelihood that neighbouring transcripts
originate from the same cell. Notably, it has shown strong performance
across datasets and has been reported to outperform the default
segmentation provided in Xenium workflows^34^, highlighting its
practical utility and growing adoption.</p>
<h2 id="cell-phenotyping">Cell phenotyping</h2>
<p>Cell phenotyping is the process of assigning biological identities to
individual cells based on their molecular profiles, such as gene or
protein expression, and serves as a critical step in interpreting
spatial omics data.</p>
<h3 id="spatial-proteomics_2">Spatial proteomics</h3>
<p>Unlike transcriptomic approaches, spatial proteomics typically profiles
a pre-selected panel of $\sim$<code>&lt;!-- --&gt;</code>{=html}30--50 protein markers,
chosen based on the biological question. This reduced and curated
feature space simplifies downstream computational analysis but increases
reliance on prior biological knowledge for interpreting clusters^6^.</p>
<p>Commonly used clustering algorithms include Cytosplore, a GUI which
leverages [HSNE]{acronym-label="HSNE"
acronym-form="singular+short"}^35^, Phenograph that builds a shared
nearest neighbor graph and uses Louvain algorithm to partition of the
graph into communities^35^, and FlowSOM that applies
[SOM]{acronym-label="SOM" acronym-form="singular+short"}^36,37^.</p>
<p>In addition to unsupervised clustering, other strategies for phenotyping
include: Manual gating, where marker thresholds are used to define known
populations based on expert knowledge; Supervised machine learning
models, such as Random Forests, which classify cells using labelled
training data and reference mapping, where new datasets are aligned to
previously annotated references to infer phenotypes.</p>
<h3 id="spatial-transcriptomics_2">Spatial transcriptomics</h3>
<p>Spatial transcriptomics datasets that approach single-cell resolution
often adopt analysis pipelines developed for
[scRNA]{acronym-label="scRNA" acronym-form="singular+short"}. This
involves several key steps:</p>
<p>The process begins with data preprocessing, where cells of low quality
are removed through quality control steps. Following this, normalization
is applied---most commonly scaling gene counts to 10,000 per cell and
applying a log-transformation---to standardize data across cells. Since
these datasets are high-dimensional, dimensionality reduction is used to
make the data more manageable. [PCA]{acronym-label="PCA"
acronym-form="singular+short"} is commonly applied first to identify the
most informative gene expression patterns. For visualization and further
analysis, nonlinear techniques like t-SNE and UMAP are used to project
the data into two or three dimensions while preserving its underlying
structure^38^.</p>
<p>Next, clustering algorithms group similar cells together. This is
usually done by building a [KNN]{acronym-label="KNN"
acronym-form="singular+short"} graph in the PCA-reduced space. Each cell
is connected to its K most similar neighbours, and clustering algorithms
such as Louvain^39^ and Leiden^40^, often with better performance^41^
are applied to identify densely connected communities within the graph.
These clusters are assumed to represent groups of cells with similar
transcriptional profiles, often corresponding to distinct cell types or
states.</p>
<p>Once clusters are identified, cell type annotation is performed to
assign biological identities to the groups of cells. This can be done
either manually or automatically.</p>
<p>Manual annotation relies on known marker genes---genes that are
characteristically expressed in specific cell types. In practice, this
can be done by checking whether known markers are expressed in each
cluster or, conversely, by identifying differentially expressed genes
within clusters and matching them to known biological signatures. While
manual annotation is transparent and interpretable, it can be
subjective, labour-intensive, and limited by the availability and
specificity of known markers^38^.</p>
<p>Alternatively, automated annotation methods are also available, which
leverage reference gene atlases and machine/deep learning models (e.g.,
CellTypist^42^), or label transfer approaches (e.g., Symphony^43^).
These methods provide faster and more scalable annotation but tend to be
less interpretable and dependent on the similarity between the reference
and the query data^38^.</p>
<p>Currently, automated approaches are not yet standard for spatial
transcriptomics, particularly in cases where the data is limited by
lower gene counts, targeted panels, or lower sequencing depth compared
to single-cell RNA. Additionally, many spatial datasets do not align
well with existing reference atlases due to differences in tissue
context, resolution, or platform. As a result, manual annotation remains
more reliable and commonly used in spatial transcriptomics, particularly
when high-resolution spatial context and known marker expression are
available.</p>
<h2 id="cellular-neighbourhood-analysis">Cellular neighbourhood analysis</h2>
<p>Cellular neighbourhood analysis begins with the construction of a
spatial connectivity graph that captures the proximity relationships
between cells within the tissue. This spatial graph serves as the
backbone for downstream spatial statistics and interaction analyses.
Different methods can be used to construct such graphs, including
k-nearest neighbours, where each cell is connected to a fixed number of
closest neighbours; radius-based expansion, which connects all cells
within a given physical distance; and Delaunay triangulation, which uses
geometric criteria to define adjacency without imposing arbitrary
thresholds. Importantly, the same principles and methodologies for
neighbourhood analysis apply across these two modalities, despite
differences in the underlying molecular readouts^6,38^.</p>
<p>Once a graph is established, it enables the exploration of spatial
interactions between annotated cell types. A common approach involves
the computation of neighbourhood enrichment scores, which statistically
test whether specific cell types are found adjacent to each other more
or less frequently than expected by chance. These analyses rely on
permutation-based null models, which shuffle cell-type labels while
preserving tissue structure, providing a robust statistical framework to
assess enrichment or depletion of interactions^44^. Another related
method is the computation of co-occurrence scores, which estimate how
likely it is to observe specific cell-type pairs within increasing radii
around each cell. These scores reflect the conditional probability of
observing a certain cell type given the presence of another nearby,
offering an interpretable measure of spatial association across
scales^38^.</p>
<p>Alternatively, simple interaction matrices can be computed, summarizing
the raw counts of neighbouring cell-type pairs^6^. Though not
statistical tests, these matrices are useful for exploratory data
analysis.</p>
<p>Beyond pairwise interaction analyses, more integrative approaches aim to
cluster cells based on the composition of their local neighbourhoods.
One strategy involves computing, for each cell, the fraction of
surrounding cell types within its local environment (e.g., 20 nearest
neighbours). These local composition profiles can then be clustered
using unsupervised methods such as k-means or Leiden algorithms,
grouping cells into recurring spatial neighbourhoods. This approach was
introduced by studies such as Goltsev et al.^45^ and Schürch et al.^46^,
which revealed that specific combinations of neighbouring discrete cell
types are often spatially organized in conserved patterns.</p>
<p>A related method involves aggregating gene or protein expression
features across the neighbourhood, effectively capturing a summary of
the local microenvironment. These aggregated features can then serve as
the basis for clustering or downstream modelling, this is approach is
implemented for example in covariance environment (COVET)^47^,
NicheCompass, a graph deep-learning approach to identify and
quantitatively characterize niches by learning cell embeddings encoding
signalling events as spatial gene program activities^48^ and Banksy^49^.</p>
<p>Through these computational strategies, spatial neighbourhoods can be
identified and interpreted biologically as spatial niches---localized,
recurring configurations of cells and their molecular environment that
reflect functionally relevant tissue microenvironments. Spatial niches
are particularly informative in contexts such as immuno-oncology, where
immune-tumour interactions shape the progression or suppression of
disease.</p>
<h2 id="spatial-domains">Spatial domains</h2>
<p>Closely related to cellular neighbourhoods, spatial domains usually
refer to broader, tissue-scale regions characterized by coherent gene or
protein expression patterns and underlying structural organization^38^.
While cellular neighbourhoods capture the immediate microenvironment
around a cell---defined by local interactions and spatial
proximity---spatial domains extend this concept to larger anatomical or
functional areas of tissue. These regions often consist of diverse cell
types and multiple neighbourhood configurations, working together to
support complex biological functions.</p>
<p>Because of the overlap between microenvironmental patterns and larger
spatial structures, some computational approaches can identify both
neighbourhoods and domains using similar principles. These methods
generally integrate molecular profiles with spatial information,
allowing for the detection of both fine-grained and broader-scale tissue
organization. A common strategy involves combining a cell's individual
gene or protein expression with the aggregated expression from its
surrounding neighbours. This allows the model to capture both intrinsic
cell identity and the influence of the local microenvironment, which is
particularly useful in tissues where cells of the same type are
dispersed rather than spatially clustered.</p>
<p>A wide range of computational strategies has been developed for domain
segmentation. Some early methods relied on spatial smoothing techniques,
such as Markov Random Fields, which encourage physically proximate cells
to be assigned the same label^50,51^. This assumes that a cell's
transcriptome resembles the average of its domain, although this may not
always hold true in tissues where multiple cell types are intermixed.
Other approaches employ deep learning, particularly graph-based neural
networks that can incorporate either histological information^52,53^ or
spatial graphs derived purely from molecular and positional
data^54--56^. These methods offer flexibility and can capture complex
spatial dependencies, but their performance can vary with dataset size
and structure.</p>
<p>More recently, methods introducing hierarchical and multiscale
representations of spatial structure have emerged. For instance,
NeST^57^ identifies nested co-expression hotspots---spatially contiguous
regions that co-express subsets of genes---by simultaneously searching
across gene and spatial dimensions. This approach captures biological
structure at multiple scales and can reveal overlapping or nested
domains, without requiring prior assumptions about gene sets or spatial
resolution. Similarly, the concept of tissue schematics^58^ has been
proposed as a way to abstract spatial organization into higher-order
motifs, by identifying modular assemblies of cellular neighbourhoods.
These schematics can be used to represent tissue architecture in both
healthy and diseased states, offering insights into how local
interactions scale up to tissue-level functionality.</p>
<h2 id="spatially-variable-genes">Spatially Variable genes</h2>
<p>[SVG]{acronym-label="SVG" acronym-form="singular+short"}s are genes
whose expression displays significant spatial patterning across a
tissue. Identifying SVGs reveals insights into tissue architecture,
cell--cell communication, and local microenvironmental influences,
extending beyond what is captured by cell types or spatial domains
alone. These spatial patterns may arise from gradients in signalling
molecules, regional functional differences, or heterogeneous cell
compositions^38^. Notably, SVG detection does not rely on cell
segmentation, making it applicable across different spatial omics
technologies.</p>
<p>Several computational methods have been developed to detect SVGs by
decomposing gene expression variability into spatial and non-spatial
components. A widely used statistic is Moran's I, which quantifies
spatial autocorrelation by measuring how similar gene expression is
between neighbouring spots^59^. Model-based approaches like
SpatialDE^60^, trendseek^61^, SPARK^62^, and SPARK-X^63^ use Gaussian
processes or spatial statistical models to test for spatially structured
expression while accounting for noise and overdispersion. While these
tools test each gene independently and return p-values, they often
overlook spatial domain context, which can limit biological
interpretability. Other strategies take different modelling
perspectives: Sepal^64^ applies a Gaussian diffusion process, scGCO^65^
uses graph cuts to detect spatial expression boundaries, and SpaGCN^53^,
defines both domains and SVGs integrating histology and spatial
proximity through graph convolutional networks.</p>
<p>Importantly, the identification of SVGs is modality-agnostic and
applicable to both spatial transcriptomics and spatial proteomics.
Regardless of whether gene expression or protein abundance is measured,
spatially variable features represent key molecular signatures of tissue
structure and function, and form an essential layer of spatial omics
analysis.</p>
<h2 id="functional-analysis">Functional analysis</h2>
<p>Understanding how spatial context shapes cellular function is an
increasingly important focus in spatial omics. Beyond identifying cell
types, neighbourhoods, or spatially variable genes, functional analysis
aims to reveal how cells operate and interact in situ. This includes
investigating intracellular signalling pathways, [TF]{acronym-label="TF"
acronym-form="singular+short"} activity, and particularly
c[CCC]{acronym-label="CCC" acronym-form="singular+short"} events---often
inferred from curated interaction networks derived from transcriptomics
data^66,67^.</p>
<p>A broad landscape of computational tools has emerged for CCC
analysis^67--76^, reflecting the growing complexity and richness of
spatial omics data. Broadly, these methods fall into two sections:
identifying pairs of genes that interact, such that expression of the
gene in one cell influences that of the other gene in others; and
identifying pairs of cells in which that gene pair interacts^77^.</p>
<p>Most methods for CCC leverage [L-R]{acronym-label="L-R"
acronym-form="singular+short"} interactions, relying heavily on prior
biological knowledge, often curated into databases such as
CellPhoneDB^69^, OmniPath^78^, and CellChat^70^. These databases
catalogue known signalling pathways and interaction pairs from the
literature. Using such resources, CCC inference can be extended to the
spatial context by identifying L--R pairs co-expressed in nearby
cells^67^ for example using spatial co-expression^67,73^, or
incorporating different approaches such as optimal transport
frameworks^72^ or Bayesian [MIL]{acronym-label="MIL"
acronym-form="singular+short"}^76^ to more precisely link cells by both
location and expression.</p>
<p>Complementing these prior knowledge-driven approaches are data-driven
methods that model spatial gene expression to discover novel
interactions. These models, like NCEM^68^, GCNG^75^ or SVCA^79^ and
Misty^80^ (while not specific for CCC), aim to capture interactions that
explain spatial expression variance across multiple genes. They enable
inference of new communication patterns not captured in curated L--R
databases, though their accuracy depends on model design and training
data.</p>
<p>Furthermore, some CCC frameworks estimate global co-localization across
entire tissue sections^68,71,80^, and others focus on local cell-cell
proximity^72,73^.</p>
<p>In parallel, there is increasing interest in inferring intracellular
functional activity---such as pathway activation, TF activity, or gene
set enrichment---within individual cells or regions. Tools like
decouplR^81^ apply prior knowledge from pathway perturbation
signatures^82^ or regulatory networks^83^ to estimate these functional
states at single-cell or spot level. As with CCC, these functional
scores can then be spatially mapped. These approaches are currently more
mature for spatial transcriptomics, where broader gene coverage enables
more reliable functional inference. In contrast, spatial proteomics
remains limited by smaller marker panels and less comprehensive prior
knowledge, constraining the resolution of functional state estimation.</p>
<p>While spatial omics provides a key advantage over single-cell RNA
through direct measurement of cell proximity---eliminating the need for
probabilistic neighbourhood modelling and enabling exclusion of
implausible, long-range interactions---this often comes with trade-offs.
Platforms with true cellular resolution (e.g., CosMx, Xenium) may
capture fewer genes, complicating pathway-level analyses and downstream
functional interpretation. Moreover, the heavy reliance on curated
databases across most CCC methods introduces variability and potential
inconsistencies, as predictions can differ significantly depending on
the resource used.</p>
<p>Ultimately, understanding how a cell's functional state is shaped by its
environment---and how it, in turn, influences surrounding cells---is a
central and still largely untapped frontier in spatial biology. As
methods advance, this bidirectional view of cellular function in context
promises to transform our understanding of tissue organization, disease
progression, and therapeutic targeting.</p>
<h2 id="how-to-distinguish-between-sample-conditions">How to distinguish between sample conditions</h2>
<p>While the tasks described in the previous sections---such as
preprocessing, cell segmentation, and feature extraction---lay the
foundation for spatial omics analysis, deriving meaningful biological
insights often requires comparing groups, such as different disease
states, treatment responses, or tissue types.</p>
<h3 id="summary-statistics">Summary statistics</h3>
<p>One of the earliest approaches involves aggregating spatial features
across samples and comparing them using statistical summaries. For
example, scores for cell--cell communication, number of neighbours, or
other spatial statistics can be averaged per sample and used to detect
differences between conditions^67,80,84^. However, this strategy is
often too simplistic, as it can blur important heterogeneity by
averaging out spatially localized effects.</p>
<h3 id="matrix-factorization-methods">Matrix factorization methods</h3>
<p>Matrix factorization methods provide a more nuanced alternative. These
approaches reduce high-dimensional data into a smaller set of latent
factors that capture major patterns of variation. Classical approaches
like PCA achieve this through linear decompositions, but newer tools
like [MOFA]{acronym-label="MOFA" acronym-form="singular+short"}^85--87^,
MEFISTO^88^, and DIALOGUE^89^ extend the concept to handle multiple data
types, structured variation, or intercellular coordination. These
methods can incorporate spatial information embedded in the matrix.</p>
<p>MOFA and its variants allow joint analysis of multi-omic datasets,
identifying latent factors that capture both shared and group-specific
variation. Other tools like DIALOGUE^89^ and scITD^90^ focus on
identifying coordinated gene programs across multiple cell types,
enabling the characterization of multicellular processes in an
unsupervised fashion.</p>
<p>[NMF]{acronym-label="NMF" acronym-form="singular+short"} provides a more
interpretable, parts-based representation, especially useful for
identifying additive biological signals like distinct cell states or
spatial domains. Spatially-aware versions of NMF, such as
[NSF]{acronym-label="NSF" acronym-form="singular+short"}, extend this
idea by directly incorporating spatial coordinates, better capturing
localized gene expression patterns^91^.</p>
<p>These matrix-based methods not only enhance the ability to uncover
biologically relevant spatial and intercellular patterns, but also
enable unsupervised identification of group-level differences---whether
driven by disease, environment, or treatment---without requiring
explicit labels.</p>
<h3 id="machine-learning-and-deep-learning-approaches">Machine Learning and Deep Learning approaches</h3>
<p>Beyond matrix factorization, supervised [ML]{acronym-label="ML"
acronym-form="singular+short"} and [DL]{acronym-label="DL"
acronym-form="singular+short"} methods are increasingly being explored
to classify samples or predict disease conditions using spatial and
single-cell omics data. These models are particularly well-suited to
capturing nonlinear relationships and subtle patterns in
high-dimensional datasets. However, their application in this domain
remains relatively limited---mainly due to the scarcity of large,
well-annotated datasets needed to train robust deep models. While DL
approaches typically require thousands of samples to achieve
generalizability, spatial omics datasets have only recently begun to
reach that scale.</p>
<p>It's worth noting that DL has been widely adopted in other stages of the
spatial omics pipeline---such as image preprocessing, segmentation,
domain identification, phenotyping, and modelling of cell--cell
communication---but its use for direct classification or outcome
prediction is still sparse.</p>
<p>Among early efforts in this direction, NaroNet^92^ introduced a patch
contrastive learning strategy combined with graph representations to
predict patient outcomes from IMC data. In the same cohort, Fu et
al.^93^ proposed a deep multimodal graph-based network that integrates
IMC data with clinical variables to predict cancer survival. In another
example, Risom et al.^94^ applied a random forest classifier to a MIBI
dataset of ductal carcinoma in situ (DCIS), using over 400 spatial
features---including tissue compartment enrichment and TME
morphometrics---to distinguish between progressors and non-progressors.</p>
<p>A more recent and notable advance is S3-CIMA^95^, a weakly supervised,
single-layer convolutional neural network that learns disease-specific
spatial compositions of the tumour microenvironment. By modelling local
cell-type organizations from high-dimensional proteomic imaging data
(IMC and CODEX), it enables the discovery of outcome-associated
microenvironments in colorectal cancer. Similarly, graph deep learning
has been used to predict prognosis in gastric cancer, where Cell-Graphs
built from multiplexed immunohistochemistry (mIHC) data enable prognosis
prediction from spatial arrangements of cell types^96^.</p>
<p>Important to note is that DL methods are already well-established in
computational pathology and digital histopathology, where large
annotated datasets and well-defined visual features have allowed CNNs to
thrive in image classification, segmentation, and prognosis prediction
tasks^97,98^.</p>
<h2 id="frameworks-and-tools-for-spatial-omics-analysis">Frameworks and tools for spatial omics analysis</h2>
<p>A growing ecosystem of software tools supports the analysis of
single-cell and spatial omics data. Seurat (R)^99^ and Scanpy
(Python)^100^ are widely used for single-cell analysis. Scanpy is built
around the efficient AnnData structure^101^, while Seurat uses its own
SeuratObject. Dedicated spatial omics tools such as Giotto (R)^102^ and
Squidpy (Python)^84^ offer integrated workflows for spatial statistics,
neighbourhood analysis, and visualization with also new data frameworks
like SpatialData (Python)^103^ emerging to better support spatial
modalities. Napari^104^, a general-purpose image viewer, complements
these tools with interactive, high-dimensional image
visualization---useful for working with spatial coordinates and tissue
images.</p>
<p>Python and R remain the dominant programming languages in this space.
Python is increasingly favoured for spatial omics due to its speed,
memory efficiency, and compatibility with deep learning and image
processing (e.g., PyTorch), while R remains popular for exploratory
analysis and visualization^105^. Meanwhile, Julia is gaining attention
for its performance, with tools like Baysor^25^ highlighting its
potential in spatial omics analysis^106^.</p>
<p>Given the rapid growth of tools---and the risk of incompatibilities in
data formats, APIs, and user interfaces---standardization efforts like
scverse^107^ have emerged. These initiatives promote well-maintained,
interoperable core functionality, supporting a more cohesive and
collaborative spatial omics software ecosystem.</p>
<h2 id="closing-remarks">Closing remarks</h2>
<p>This review has focused on spatial omics methods that operate on the
basis of cell-defined units. However, it is important to note that many
of these approaches can also be applied at the transcript level,
bypassing the need for explicit cell segmentation---this is particularly
true for tasks such as domain identification. While cell-based analysis
remains the prevailing standard in spatial omics, alternative strategies
that complement or replace cell segmentation are gaining ground^56,108^.
This shift is partly driven by the technical difficulty of accurately
segmenting individual cells, especially in complex tissues where cells
may be overlapping, densely packed, or poorly defined. Acknowledging
these challenges, this thesis introduces novel approaches for cell-free
analysis of spatial transcriptomics data, as elaborated in
Chapter <a href="#ch:gridgen">[ch:gridgen]</a>{reference-type="ref"
reference="ch:gridgen"}.</p>
<p>Furthermore, this review has specifically addressed computational
methods applicable to single-cell resolution spatial data, and does not
cover broader-scale approaches such as spatial deconvolution or data
imputation, which are more relevant to spot-based or lower-resolution
platforms.</p>
<p>Even within the focused scope of single-cell approaches, many valuable
tools and developments could not be fully covered, reflecting the sheer
volume and velocity of innovation in the field.
Figure <a href="#fig:review">1</a>{reference-type="ref" reference="fig:review"}
provides a visual overview of the spatial omics methods discussed in
this review, highlighting the diversity and complexity of the
computational landscape. Nodes are organized by their functional role in
the analysis pipeline and scaled by citation count, illustrating both
methodological clustering and community impact. Furthermore, an
interactive visualization is available at
<a href="https://marta-seq.github.io/SOME/">https://marta-seq.github.io/SOME/</a>. The increasing availability of
spatially resolved data across multiple modalities has fuelled an
avalanche of computational methods, making it increasingly difficult for
researchers to keep pace and make informed decisions about which tools
best suit their needs. In this evolving landscape, there is a growing
need for \"living reviews\"^105^, curated repositories, and
community-driven benchmarking^98^ efforts that can adapt to the field's
rapid progress.</p>
<figure id="fig:review">
<embed src="Chapters/background/review.pdf" />
<figcaption>Graph overview of spatial omics methods analysed in this
review. Each node represents a method included in this review, with the
colour indicating its role in the spatial omics analysis pipeline (e.g.,
orange – Preprocessing, blue – Cell Segmentation, etc.) and the size of
the bubble proportional to its citation count, reflecting community
adoption. Nodes are grouped spatially by conceptual similarity and
method type. Only full spatial omics methods are shown, excluding
foundational algorithms or reused modules from unrelated pipelines. This
layout reveals the landscape and complexity of spatial omics
development. The interactive version of this graph is available at: <a
href="https://marta-seq.github.io/SOME/"
class="uri">https://marta-seq.github.io/SOME/</a>. This approach can be
extended to incorporate newly published methods or customized for other
use cases.</figcaption>
</figure>

<p>::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::: {#refs .references .csl-bib-body entry-spacing="0" line-spacing="2"}
::: {#ref-P6_baharlou_mass_2019 .csl-entry}
[1. ]{.csl-left-margin}[Baharlou, H., Canete, N. P., Cunningham, A. L.,
Harman, A. N. &amp; Patrick, E. <a href="https://doi.org/10.3389/fimmu.2019.02657">Mass Cytometry Imaging for the Study of
Human Diseases---Applications and Data Analysis
Strategies</a>. <em>Frontiers in
Immunology</em> <strong>10</strong>, 2657 (2019).]{.csl-right-inline}
:::</p>
<p>::: {#ref-P7_baranski_maui_2021 .csl-entry}
[2. ]{.csl-left-margin}[Baranski, A. <em>et al.</em> <a href="https://doi.org/10.1371/journal.pcbi.1008887">MAUI (MBI Analysis User
Interface)---An image processing pipeline for Multiplexed Mass Based
Imaging</a>. <em>PLOS
Computational Biology</em> <strong>17</strong>, e1008887 (2021).]{.csl-right-inline}
:::</p>
<p>::: {#ref-P8_chevrier_compensation_2018 .csl-entry}
[3. ]{.csl-left-margin}[Chevrier, S. <em>et al.</em> <a href="https://doi.org/10.1016/j.cels.2018.02.010">Compensation of Signal
Spillover in Suspension and Imaging Mass
Cytometry</a>. <em>Cell Systems</em>
<strong>6</strong>, 612--620.e5 (2018).]{.csl-right-inline}
:::</p>
<p>::: {#ref-P9_12_milosevic_different_2023 .csl-entry}
[4. ]{.csl-left-margin}[Milosevic, V. <a href="https://doi.org/10.1093/bioadv/vbad046">Different approaches to Imaging
Mass Cytometry data analysis</a>.
<em>Bioinformatics Advances</em> <strong>3</strong>, vbad046 (2023).]{.csl-right-inline}
:::</p>
<p>::: {#ref-P11_wang_multiplexed_2019 .csl-entry}
[5. ]{.csl-left-margin}[Wang, Y. J. <em>et al.</em> <a href="https://doi.org/10.1016/j.cmet.2019.01.003">Multiplexed In Situ
Imaging Mass Cytometry Analysis of the Human Endocrine Pancreas and
Immune System in Type 1
Diabetes</a>. <em>Cell Metabolism</em>
<strong>29</strong>, 769--783.e4 (2019).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B79_P15_S20_steinbock2023 .csl-entry}
[6. ]{.csl-left-margin}[Windhager, J. <em>et al.</em> <a href="https://doi.org/10.1038/s41596-023-00881-0">An end-to-end workflow
for multiplexed image processing and
analysis</a>. <em>Nature
Protocols</em> <strong>18</strong>, 3565--3613 (2023).]{.csl-right-inline}
:::</p>
<p>::: {#ref-P13_keren_structured_2018 .csl-entry}
[7. ]{.csl-left-margin}[Keren, L. <em>et al.</em> <a href="https://doi.org/10.1016/j.cell.2018.08.039">A Structured Tumor-Immune
Microenvironment in Triple Negative Breast Cancer Revealed by
Multiplexed Ion Beam
Imaging</a>. <em>Cell</em> <strong>174</strong>,
1373--1387.e19 (2018).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B81_P14_rendeiro2021 .csl-entry}
[8. ]{.csl-left-margin}[Rendeiro, A. F. <em>et al.</em> <a href="https://doi.org/10.1038/s41586-021-03475-6">The spatial landscape
of lung pathology during COVID-19
progression</a>. <em>Nature</em>
<strong>593</strong>, 564--569 (2021).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B82_P16_ilastik2019 .csl-entry}
[9. ]{.csl-left-margin}[Berg, S. <em>et al.</em> <a href="https://doi.org/10.1038/s41592-019-0582-9">Ilastik: Interactive machine
learning for (bio)image
analysis</a>. <em>Nature Methods</em>
<strong>16</strong>, 1226--1232 (2019).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B83_P17_25_ijsselsteijn2021 .csl-entry}
[10. ]{.csl-left-margin}[Ijsselsteijn, M. E., Somarakis, A., Lelieveldt,
B. P. F., Höllt, T. &amp; De Miranda, N. F. C. C. <a href="https://doi.org/10.1002/cyto.a.24480">Semi‐automated background
removal limits data loss and normalizes imaging mass cytometry
data</a>. <em>Cytometry Part A</em> <strong>99</strong>,
1187--1197 (2021).]{.csl-right-inline}
:::</p>
<p>::: {#ref-P10_lu_imc-denoise_2023 .csl-entry}
[11. ]{.csl-left-margin}[Lu, P. <em>et al.</em> <a href="https://doi.org/10.1038/s41467-023-37123-6">IMC-Denoise: A content aware
denoising pipeline to enhance Imaging Mass
Cytometry</a>. <em>Nature
Communications</em> <strong>14</strong>, 1601 (2023).]{.csl-right-inline}
:::</p>
<p>::: {#ref-P19_krull_noise2void_2019 .csl-entry}
[12. ]{.csl-left-margin}[Krull, A., Buchholz, T.-O. &amp; Jug, F.
Noise2Void - Learning Denoising From Single Noisy Images. in <em>2019
IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>
2124--2132 (IEEE, Long Beach, CA, USA, 2019).
doi:<a href="https://doi.org/10.1109/CVPR.2019.00223">10.1109/CVPR.2019.00223</a>.]{.csl-right-inline}
:::</p>
<p>::: {#ref-P26_S21_mcquin_cellprofiler_2018 .csl-entry}
[13. ]{.csl-left-margin}[McQuin, C. <em>et al.</em> <a href="https://doi.org/10.1371/journal.pbio.2005970">CellProfiler 3.0:
Next-generation image processing for
biology</a>. <em>PLOS Biology</em>
<strong>16</strong>, e2005970 (2018).]{.csl-right-inline}
:::</p>
<p>::: {#ref-S7_cellprofiler2006 .csl-entry}
[14. ]{.csl-left-margin}[Carpenter, A. E. <em>et al.</em> <a href="https://doi.org/10.1186/gb-2006-7-10-r100">CellProfiler: Image
analysis software for identifying and quantifying cell
phenotypes</a>. <em>Genome Biology</em>
<strong>7</strong>, R100 (2006).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B88_schindelin_fiji_2012 .csl-entry}
[15. ]{.csl-left-margin}[Schindelin, J. <em>et al.</em> <a href="https://doi.org/10.1038/nmeth.2019">Fiji: An open-source
platform for biological-image
analysis</a>. <em>Nature Methods</em> <strong>9</strong>,
676--682 (2012).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B89_zerocostDL4MIC .csl-entry}
[16. ]{.csl-left-margin}[Von Chamier, L. <em>et al.</em> <a href="https://doi.org/10.1038/s41467-021-22518-0">Democratising deep
learning for microscopy with
ZeroCostDL4Mic</a>. <em>Nature
Communications</em> <strong>12</strong>, 2276 (2021).]{.csl-right-inline}
:::</p>
<p>::: {#ref-S5_mesmer2022 .csl-entry}
[17. ]{.csl-left-margin}[Greenwald, N. F. <em>et al.</em> <a href="https://doi.org/10.1038/s41587-021-01094-0">Whole-cell
segmentation of tissue images with human-level performance using
large-scale data annotation and deep
learning</a>. <em>Nature
Biotechnology</em> <strong>40</strong>, 555--565 (2022).]{.csl-right-inline}
:::</p>
<p>::: {#ref-S6_cellpose2021 .csl-entry}
[18. ]{.csl-left-margin}[Stringer, C., Wang, T., Michaelos, M. &amp;
Pachitariu, M. <a href="https://doi.org/10.1038/s41592-020-01018-x">Cellpose: A generalist algorithm for cellular
segmentation</a>. <em>Nature
Methods</em> <strong>18</strong>, 100--106 (2021).]{.csl-right-inline}
:::</p>
<p>::: {#ref-S16_cellpose2 .csl-entry}
[19. ]{.csl-left-margin}[Pachitariu, M. &amp; Stringer, C. <a href="https://doi.org/10.1038/s41592-022-01663-4">Cellpose 2.0:
How to train your own
model</a>. <em>Nature Methods</em>
<strong>19</strong>, 1634--1641 (2022).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B93_lee_cellseg_2022 .csl-entry}
[20. ]{.csl-left-margin}[Lee, M. Y. <em>et al.</em> <a href="https://doi.org/10.1186/s12859-022-04570-9">CellSeg: A robust,
pre-trained nucleus segmentation and pixel quantification software for
highly multiplexed fluorescence
images</a>. <em>BMC
Bioinformatics</em> <strong>23</strong>, 46 (2022).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B94_mcmicro2022 .csl-entry}
[21. ]{.csl-left-margin}[Schapiro, D. <em>et al.</em> <a href="https://doi.org/10.1038/s41592-021-01308-y">MCMICRO: A scalable,
modular image-processing pipeline for multiplexed tissue
imaging</a>. <em>Nature Methods</em>
<strong>19</strong>, 311--315 (2022).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B95_matisse2021 .csl-entry}
[22. ]{.csl-left-margin}[Baars, M. J. D. <em>et al.</em> <a href="https://doi.org/10.1186/s12915-021-01043-y">MATISSE: A method for
improved single cell segmentation in imaging mass
cytometry</a>. <em>BMC Biology</em>
<strong>19</strong>, 99 (2021).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B96_splinedist2020 .csl-entry}
[23. ]{.csl-left-margin}[Mandal, S. &amp; Uhlmann, V. SplineDist: Automated
Cell Segmentation With Spline Curves. (2020)
doi:<a href="https://doi.org/10.1101/2020.10.27.357640">10.1101/2020.10.27.357640</a>.]{.csl-right-inline}
:::</p>
<p>::: {#ref-B97_stardist2018 .csl-entry}
[24. ]{.csl-left-margin}[Schmidt, U., Weigert, M., Broaddus, C. &amp; Myers,
G. Cell Detection with Star-convex Polygons. (2018)
doi:<a href="https://doi.org/10.48550/ARXIV.1806.03535">10.48550/ARXIV.1806.03535</a>.]{.csl-right-inline}
:::</p>
<p>::: {#ref-G8_baysor .csl-entry}
[25. ]{.csl-left-margin}[Petukhov, V. <em>et al.</em> <a href="https://doi.org/10.1038/s41587-021-01044-w">Cell segmentation in
imaging-based spatial
transcriptomics</a>. <em>Nature
Biotechnology</em> <strong>40</strong>, 345--354 (2022).]{.csl-right-inline}
:::</p>
<p>::: {#ref-G9_ssam .csl-entry}
[26. ]{.csl-left-margin}[Park, J. <em>et al.</em> <a href="https://doi.org/10.1038/s41467-021-23807-4">Cell segmentation-free
inference of cell types from in situ transcriptomics
data</a>. <em>Nature
Communications</em> <strong>12</strong>, 3545 (2021).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B100_prabhakaran_sparcle_2022 .csl-entry}
[27. ]{.csl-left-margin}[Prabhakaran, S. <a href="https://doi.org/10.1093/bioadv/vbac048">Sparcle: Assigning transcripts
to cells in multiplexed images</a>.
<em>Bioinformatics Advances</em> <strong>2</strong>, vbac048 (2022).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B101_clustermap_2021 .csl-entry}
[28. ]{.csl-left-margin}[He, Y. <em>et al.</em> <a href="https://doi.org/10.1038/s41467-021-26044-x">ClusterMap for multi-scale
clustering analysis of spatial gene
expression</a>. <em>Nature
Communications</em> <strong>12</strong>, 5909 (2021).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B102_ficture_2024 .csl-entry}
[29. ]{.csl-left-margin}[Si, Y. <em>et al.</em> <a href="https://doi.org/10.1038/s41592-024-02415-2">FICTURE: Scalable
segmentation-free analysis of submicron-resolution spatial
transcriptomics</a>. <em>Nature
Methods</em> <strong>21</strong>, 1843--1854 (2024).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B103_bidcell_2024 .csl-entry}
[30. ]{.csl-left-margin}[Fu, X. <em>et al.</em> <a href="https://doi.org/10.1038/s41467-023-44560-w">BIDCell: Biologically-informed
self-supervised learning for segmentation of subcellular spatial
transcriptomics data</a>.
<em>Nature Communications</em> <strong>15</strong>, 509 (2024).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B104_defard2024 .csl-entry}
[31. ]{.csl-left-margin}[Defard, T. <em>et al.</em> <a href="https://doi.org/10.1038/s42003-024-06480-3">A point cloud segmentation
framework for image-based spatial
transcriptomics</a>.
<em>Communications Biology</em> <strong>7</strong>, 823 (2024).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B105_spage2vec2021 .csl-entry}
[32. ]{.csl-left-margin}[Partel, G. &amp; Wählby, C. <a href="https://doi.org/10.1111/febs.15572">Spage2vec:
Unsupervised representation of localized spatial gene expression
signatures</a>. <em>The FEBS Journal</em>
<strong>288</strong>, 1859--1870 (2021).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B106_qian_probabilistic_2020 .csl-entry}
[33. ]{.csl-left-margin}[Qian, X. <em>et al.</em> <a href="https://doi.org/10.1038/s41592-019-0631-4">Probabilistic cell typing
enables fine mapping of closely related cell types in
situ</a>. <em>Nature Methods</em>
<strong>17</strong>, 101--106 (2020).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B107_optXenium2025 .csl-entry}
[34. ]{.csl-left-margin}[Marco Salas, S. <em>et al.</em> <a href="https://doi.org/10.1038/s41592-025-02617-2">Optimizing Xenium In
Situ data utility by quality assessment and best-practice analysis
workflows</a>. <em>Nature Methods</em>
<strong>22</strong>, 813--823 (2025).]{.csl-right-inline}
:::</p>
<p>::: {#ref-S17_imacyte .csl-entry}
[35. ]{.csl-left-margin}[Van Unen, V. <em>et al.</em> <a href="https://doi.org/10.1038/s41467-017-01689-9">Visual analysis of mass
cytometry data by hierarchical stochastic neighbour embedding reveals
rare cell types</a>. <em>Nature
Communications</em> <strong>8</strong>, 1740 (2017).]{.csl-right-inline}
:::</p>
<p>::: {#ref-S19_flowsom2015 .csl-entry}
[36. ]{.csl-left-margin}[Van Gassen, S. <em>et al.</em> <a href="https://doi.org/10.1002/cyto.a.22625">FlowSOM: Using
self‐organizing maps for visualization and interpretation of cytometry
data</a>. <em>CytometryPartA</em> <strong>87</strong>,
636--645 (2015).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B111_flowSOMprotocol2021 .csl-entry}
[37. ]{.csl-left-margin}[Quintelier, K. <em>et al.</em> <a href="https://doi.org/10.1038/s41596-021-00550-0">Analyzing
high-dimensional cytometry data using
FlowSOM</a>. <em>Nature Protocols</em>
<strong>16</strong>, 3775--3801 (2021).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B112_bestPractices2023 .csl-entry}
[38. ]{.csl-left-margin}[Heumos, L. <em>et al.</em> <a href="https://doi.org/10.1038/s41576-023-00586-w">Best practices for
single-cell analysis across
modalities</a>. <em>Nature Reviews
Genetics</em> <strong>24</strong>, 550--572 (2023).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B113_blondel2008 .csl-entry}
[39. ]{.csl-left-margin}[Blondel, V. D., Guillaume, J.-L., Lambiotte, R.
&amp; Lefebvre, E. <a href="https://doi.org/10.1088/1742-5468/2008/10/P10008">Fast unfolding of communities in large
networks</a>. <em>Journal of
Statistical Mechanics: Theory and Experiment</em> <strong>2008</strong>, P10008
(2008).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B114_waltman2013 .csl-entry}
[40. ]{.csl-left-margin}[Waltman, L. &amp; Van Eck, N. J. <a href="https://doi.org/10.1140/epjb/e2013-40829-0">A smart local
moving algorithm for large-scale modularity-based community
detection</a>. <em>The European
Physical Journal B</em> <strong>86</strong>, 471 (2013).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B115_louvain_leiden2019 .csl-entry}
[41. ]{.csl-left-margin}[Traag, V. A., Waltman, L. &amp; Van Eck, N. J.
<a href="https://doi.org/10.1038/s41598-019-41695-z">From Louvain to Leiden: Guaranteeing well-connected
communities</a>. <em>Scientific
Reports</em> <strong>9</strong>, (2019).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B116_dominguez2022 .csl-entry}
[42. ]{.csl-left-margin}[Domínguez Conde, C. <em>et al.</em> <a href="https://doi.org/10.1126/science.abl5197">Cross-tissue
immune cell analysis reveals tissue-specific features in
humans</a>. <em>Science</em> <strong>376</strong>,
eabl5197 (2022).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B117_symphony .csl-entry}
[43. ]{.csl-left-margin}[Kang, J. B. <em>et al.</em> <a href="https://doi.org/10.1038/s41467-021-25957-x">Efficient and precise
single-cell reference atlas mapping with
Symphony</a>. <em>Nature
Communications</em> <strong>12</strong>, 5890 (2021).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B118_histocat_2017 .csl-entry}
[44. ]{.csl-left-margin}[Schapiro, D. <em>et al.</em> <a href="https://doi.org/10.1038/nmeth.4391">[histoCAT]{.nocase}:
Analysis of cell phenotypes and interactions in multiplex image
cytometry data</a>. <em>Nature Methods</em>
<strong>14</strong>, 873--876 (2017).]{.csl-right-inline}
:::</p>
<p>::: {#ref-P5_B44_S2_CODEX2018 .csl-entry}
[45. ]{.csl-left-margin}[Goltsev, Y. <em>et al.</em> <a href="https://doi.org/10.1016/j.cell.2018.07.010">Deep Profiling of Mouse
Splenic Architecture with CODEX Multiplexed
Imaging</a>. <em>Cell</em> <strong>174</strong>,
968--981.e15 (2018).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B119_schurch_coordinated_2020 .csl-entry}
[46. ]{.csl-left-margin}[Schürch, C. M. <em>et al.</em> <a href="https://doi.org/10.1016/j.cell.2020.07.005">Coordinated Cellular
Neighborhoods Orchestrate Antitumoral Immunity at the Colorectal Cancer
Invasive Front</a>. <em>Cell</em>
<strong>182</strong>, 1341--1359.e19 (2020).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B120_covet2025 .csl-entry}
[47. ]{.csl-left-margin}[Haviv, D. <em>et al.</em> <a href="https://doi.org/10.1038/s41587-024-02193-4">The covariance environment
defines cellular niches for spatial
inference</a>. <em>Nature
Biotechnology</em> <strong>43</strong>, 269--280 (2025).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B121_birk_quantitative_2025 .csl-entry}
[48. ]{.csl-left-margin}[Birk, S. <em>et al.</em> <a href="https://doi.org/10.1038/s41588-025-02120-6">Quantitative
characterization of cell niches in spatially resolved omics
data</a>. <em>Nature Genetics</em>
<strong>57</strong>, 897--909 (2025).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B_banksy_2024 .csl-entry}
[49. ]{.csl-left-margin}[Singhal, V. <em>et al.</em> <a href="https://doi.org/10.1038/s41588-024-01664-3">BANKSY unifies cell
typing and tissue domain segmentation for scalable spatial omics data
analysis</a>. <em>Nature Genetics</em>
<strong>56</strong>, 431--441 (2024).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B122_bayespace2021 .csl-entry}
[50. ]{.csl-left-margin}[Zhao, E. <em>et al.</em> <a href="https://doi.org/10.1038/s41587-021-00935-2">Spatial transcriptomics at
subspot resolution with
BayesSpace</a>. <em>Nature
Biotechnology</em> <strong>39</strong>, 1375--1384 (2021).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B123_zhu2018 .csl-entry}
[51. ]{.csl-left-margin}[Zhu, Q., Shah, S., Dries, R., Cai, L. &amp; Yuan,
G.-C. <a href="https://doi.org/10.1038/nbt.4260">Identification of spatially associated subpopulations by
combining [scRNAseq]{.nocase} and sequential fluorescence in situ
hybridization data</a>. <em>Nature
Biotechnology</em> <strong>36</strong>, 1183--1190 (2018).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B124_pham2023 .csl-entry}
[52. ]{.csl-left-margin}[Pham, D. <em>et al.</em> <a href="https://doi.org/10.1038/s41467-023-43120-6">Robust mapping of
spatiotemporal trajectories and cell--cell interactions in healthy and
diseased tissues</a>. <em>Nature
Communications</em> <strong>14</strong>, 7739 (2023).]{.csl-right-inline}
:::</p>
<p>::: {#ref-G10_b125_spagcn .csl-entry}
[53. ]{.csl-left-margin}[Hu, J. <em>et al.</em> <a href="https://doi.org/10.1038/s41592-021-01255-8">SpaGCN: Integrating gene
expression, spatial location and histology to identify spatial domains
and spatially variable genes by graph convolutional
network</a>. <em>Nature Methods</em>
<strong>18</strong>, 1342--1351 (2021).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B126_dong2022 .csl-entry}
[54. ]{.csl-left-margin}[Dong, K. &amp; Zhang, S. <a href="https://doi.org/10.1038/s41467-022-29439-6">Deciphering spatial
domains from spatially resolved transcriptomics with an adaptive graph
attention auto-encoder</a>.
<em>Nature Communications</em> <strong>13</strong>, 1739 (2022).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B127_graphst2023 .csl-entry}
[55. ]{.csl-left-margin}[Long, Y. <em>et al.</em> <a href="https://doi.org/10.1038/s41467-023-36796-3">Spatially informed
clustering, integration, and deconvolution of spatial transcriptomics
with GraphST</a>. <em>Nature
Communications</em> <strong>14</strong>, 1155 (2023).]{.csl-right-inline}
:::</p>
<p>::: {#ref-G14_P2R .csl-entry}
[56. ]{.csl-left-margin}[Andersson, A. <em>et al.</em> <a href="https://doi.org/10.1002/cyto.a.24884">Points2Regions: Fast,
interactive clustering of imaging‐based spatial transcriptomics
data</a>. <em>Cytometry Part A</em> <strong>105</strong>,
677--687 (2024).]{.csl-right-inline}
:::</p>
<p>::: {#ref-b129_nest2023 .csl-entry}
[57. ]{.csl-left-margin}[Walker, B. L. &amp; Nie, Q. <a href="https://doi.org/10.1038/s41467-023-42343-x">NeST: Nested
hierarchical structure identification in spatial transcriptomic
data</a>. <em>Nature
Communications</em> <strong>14</strong>, (2023).]{.csl-right-inline}
:::</p>
<p>::: {#ref-b130_tissueschem2022 .csl-entry}
[58. ]{.csl-left-margin}[Bhate, S. S., Barlow, G. L., Schürch, C. M. &amp;
Nolan, G. P. <a href="https://doi.org/10.1016/j.cels.2021.09.012">Tissue schematics map the specialization of immune tissue
motifs and their appropriation by
tumors</a>. <em>Cell Systems</em>
<strong>13</strong>, 109--130.e6 (2022).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B131_getis2010 .csl-entry}
[59. ]{.csl-left-margin}[Getis, A. Spatial Autocorrelation. in <em>Handbook
of Applied Spatial Analysis</em> (eds. Fischer, M. M. &amp; Getis, A.) 255--278
(Springer Berlin Heidelberg, Berlin, Heidelberg, 2010).
doi:<a href="https://doi.org/10.1007/978-3-642-03647-7_14">10.1007/978-3-642-03647-7_14</a>.]{.csl-right-inline}
:::</p>
<p>::: {#ref-B132_G12_spatialDE2018 .csl-entry}
[60. ]{.csl-left-margin}[Svensson, V., Teichmann, S. A. &amp; Stegle, O.
<a href="https://doi.org/10.1038/nmeth.4636">SpatialDE: Identification of spatially variable
genes</a>. <em>Nature Methods</em> <strong>15</strong>,
343--346 (2018).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B133_edsgard2018 .csl-entry}
[61. ]{.csl-left-margin}[Edsgärd, D., Johnsson, P. &amp; Sandberg, R.
<a href="https://doi.org/10.1038/nmeth.4634">Identification of spatial expression trends in single-cell gene
expression data</a>. <em>Nature Methods</em>
<strong>15</strong>, 339--342 (2018).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B134_sun2020 .csl-entry}
[62. ]{.csl-left-margin}[Sun, S., Zhu, J. &amp; Zhou, X. <a href="https://doi.org/10.1038/s41592-019-0701-7">Statistical
analysis of spatial expression patterns for spatially resolved
transcriptomic studies</a>.
<em>Nature Methods</em> <strong>17</strong>, 193--200 (2020).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B135_sparkX2021 .csl-entry}
[63. ]{.csl-left-margin}[Zhu, J., Sun, S. &amp; Zhou, X. <a href="https://doi.org/10.1186/s13059-021-02404-0">SPARK-X:
Non-parametric modeling enables scalable and robust detection of spatial
expression patterns for large spatial transcriptomic
studies</a>. <em>Genome Biology</em>
<strong>22</strong>, 184 (2021).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B136_sepal_2021 .csl-entry}
[64. ]{.csl-left-margin}[Andersson, A. &amp; Lundeberg, J. <a href="https://doi.org/10.1093/bioinformatics/btab164"><em>Sepal</em> :
Identifying transcript profiles with spatial patterns by diffusion-based
modeling</a>.
<em>Bioinformatics</em> <strong>37</strong>, 2644--2650 (2021).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B137_scGCO2022 .csl-entry}
[65. ]{.csl-left-margin}[Zhang, K., Feng, W. &amp; Wang, P. <a href="https://doi.org/10.1038/s41467-022-33182-3">Identification
of spatially variable genes with graph
cuts</a>. <em>Nature
Communications</em> <strong>13</strong>, 5488 (2022).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B138_armingol2024 .csl-entry}
[66. ]{.csl-left-margin}[Armingol, E., Baghdassarian, H. M. &amp; Lewis, N.
E. <a href="https://doi.org/10.1038/s41576-023-00685-8">The diversification of methods for studying cell--cell interactions
and communication</a>. <em>Nature
Reviews Genetics</em> <strong>25</strong>, 381--400 (2024).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B139_liana2024 .csl-entry}
[67. ]{.csl-left-margin}[Dimitrov, D. <em>et al.</em> <a href="https://doi.org/10.1038/s41556-024-01469-w">LIANA+ provides an
all-in-one framework for cell--cell communication
inference</a>. <em>Nature Cell
Biology</em> <strong>26</strong>, (2024).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B140_fischer2023 .csl-entry}
[68. ]{.csl-left-margin}[Fischer, D. S., Schaar, A. C. &amp; Theis, F. J.
<a href="https://doi.org/10.1038/s41587-022-01467-z">Modeling intercellular communication in tissues using spatial graphs of
cells</a>. <em>Nature
Biotechnology</em> <strong>41</strong>, 332--336 (2023).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B141_cellphonedb_2025 .csl-entry}
[69. ]{.csl-left-margin}[Troulé, K. <em>et al.</em> CellPhoneDB v5: Inferring
cell--cell communication from single-cell multiomics data. <em>Nature
Protocols</em> (2025)
doi:<a href="https://doi.org/10.1038/s41596-024-01137-1">10.1038/s41596-024-01137-1</a>.]{.csl-right-inline}
:::</p>
<p>::: {#ref-B142_cellchat2025 .csl-entry}
[70. ]{.csl-left-margin}[Jin, S., Plikus, M. V. &amp; Nie, Q. <a href="https://doi.org/10.1038/s41596-024-01045-4">CellChat for
systematic analysis of cell--cell communication from single-cell
transcriptomics</a>. <em>Nature
Protocols</em> <strong>20</strong>, 180--219 (2025).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B143_spatalk2022 .csl-entry}
[71. ]{.csl-left-margin}[Shao, X. <em>et al.</em> <a href="https://doi.org/10.1038/s41467-022-32111-8">Knowledge-graph-based
cell-cell communication inference for spatially resolved transcriptomic
data with SpaTalk</a>. <em>Nature
Communications</em> <strong>13</strong>, 4429 (2022).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B144_opttransp2023 .csl-entry}
[72. ]{.csl-left-margin}[Cang, Z. <em>et al.</em> <a href="https://doi.org/10.1038/s41592-022-01728-4">Screening cell--cell
communication in spatial transcriptomics via collective optimal
transport</a>. <em>Nature Methods</em>
<strong>20</strong>, (2023).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B145_spatialDM2023 .csl-entry}
[73. ]{.csl-left-margin}[Li, Z., Wang, T., Liu, P. &amp; Huang, Y.
<a href="https://doi.org/10.1038/s41467-023-39608-w">SpatialDM for rapid identification of spatially co-expressed
ligand--receptor and revealing cell--cell communication
patterns</a>. <em>Nature
Communications</em> <strong>14</strong>, 3995 (2023).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B146_nichenet2020 .csl-entry}
[74. ]{.csl-left-margin}[Browaeys, R., Saelens, W. &amp; Saeys, Y.
<a href="https://doi.org/10.1038/s41592-019-0667-5">NicheNet: Modeling intercellular communication by linking ligands to
target genes</a>. <em>Nature
Methods</em> <strong>17</strong>, 159--162 (2020).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B147_gcng2020 .csl-entry}
[75. ]{.csl-left-margin}[Yuan, Y. &amp; Bar-Joseph, Z. <a href="https://doi.org/10.1186/s13059-020-02214-w">GCNG: Graph
convolutional networks for inferring gene interaction from spatial
transcriptomics data</a>.
<em>Genome Biology</em> <strong>21</strong>, (2020).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B148_zhu_mapping_2024 .csl-entry}
[76. ]{.csl-left-margin}[Zhu, J. <em>et al.</em> <a href="https://doi.org/10.1038/s41592-024-02408-1">Mapping cellular interactions
from spatially resolved transcriptomics
data</a>. <em>Nature Methods</em>
<strong>21</strong>, 1830--1842 (2024).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B149_walker2022 .csl-entry}
[77. ]{.csl-left-margin}[Walker, B. L., Cang, Z., Ren, H.,
Bourgain-Chang, E. &amp; Nie, Q. <a href="https://doi.org/10.1038/s42003-022-03175-5">Deciphering tissue structure and function
using spatial
transcriptomics</a>.
<em>Communications Biology</em> <strong>5</strong>, 220 (2022).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B150_omnipath2016 .csl-entry}
[78. ]{.csl-left-margin}[Türei, D., Korcsmáros, T. &amp; Saez-Rodriguez, J.
<a href="https://doi.org/10.1038/nmeth.4077">OmniPath: Guidelines and gateway for literature-curated signaling
pathway resources</a>. <em>Nature Methods</em>
<strong>13</strong>, 966--967 (2016).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B151_svca2019 .csl-entry}
[79. ]{.csl-left-margin}[Arnol, D., Schapiro, D., Bodenmiller, B.,
Saez-Rodriguez, J. &amp; Stegle, O. <a href="https://doi.org/10.1016/j.celrep.2019.08.077">Modeling Cell-Cell Interactions from
Spatial Molecular Data with Spatial Variance Component
Analysis</a>. <em>Cell Reports</em>
<strong>29</strong>, (2019).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B152_misty2022 .csl-entry}
[80. ]{.csl-left-margin}[Tanevski, J., Flores, R. O. R., Gabor, A.,
Schapiro, D. &amp; Saez-Rodriguez, J. <a href="https://doi.org/10.1186/s13059-022-02663-5">Explainable multiview framework for
dissecting spatial relationships from highly multiplexed
data</a>. <em>Genome Biology</em>
<strong>23</strong>, (2022).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B153_decoupler2022 .csl-entry}
[81. ]{.csl-left-margin}[Badia-i-Mompel, P. <em>et al.</em>
<a href="https://doi.org/10.1093/bioadv/vbac016">[decoupleR]{.nocase}: Ensemble of computational methods to infer
biological activities from omics
data</a>. <em>Bioinformatics Advances</em>
<strong>2</strong>, vbac016 (2022).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B154_progeny2018 .csl-entry}
[82. ]{.csl-left-margin}[Schubert, M. <em>et al.</em> <a href="https://doi.org/10.1038/s41467-017-02391-6">Perturbation-response
genes reveal signaling footprints in cancer gene
expression</a>. <em>Nature
Communications</em> <strong>9</strong>, 20 (2018).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B155_collectri2023 .csl-entry}
[83. ]{.csl-left-margin}[Müller-Dott, S. <em>et al.</em> <a href="https://doi.org/10.1093/nar/gkad841">Expanding the
coverage of regulons from high-confidence prior knowledge for accurate
estimation of transcription factor
activities</a>. <em>Nucleic Acids
Research</em> <strong>51</strong>, 10934--10949 (2023).]{.csl-right-inline}
:::</p>
<p>::: {#ref-G7_squidpy .csl-entry}
[84. ]{.csl-left-margin}[Palla, G. <em>et al.</em> <a href="https://doi.org/10.1038/s41592-021-01358-2">Squidpy: A scalable
framework for spatial omics
analysis</a>. <em>Nature Methods</em>
<strong>19</strong>, 171--178 (2022).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B157_MOFA2018 .csl-entry}
[85. ]{.csl-left-margin}[Argelaguet, R. <em>et al.</em> <a href="https://doi.org/10.15252/msb.20178124">Multi‐Omics Factor
Analysis---a framework for unsupervised integration of multi‐omics data
sets</a>. <em>Molecular Systems
Biology</em> <strong>14</strong>, e8124 (2018).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B158_mofa+2020 .csl-entry}
[86. ]{.csl-left-margin}[Argelaguet, R. <em>et al.</em> <a href="https://doi.org/10.1186/s13059-020-02015-1">MOFA+: A statistical
framework for comprehensive integration of multi-modal single-cell
data</a>. <em>Genome Biology</em>
<strong>21</strong>, (2020).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B159_MOFAcell2023 .csl-entry}
[87. ]{.csl-left-margin}[Ramirez Flores, R. O., Lanzer, J. D., Dimitrov,
D., Velten, B. &amp; Saez-Rodriguez, J. <a href="https://doi.org/10.7554/eLife.93161">Multicellular factor analysis of
single-cell data for a tissue-centric understanding of
disease</a>. <em>eLife</em> <strong>12</strong>, e93161
(2023).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B160_mefisto2022 .csl-entry}
[88. ]{.csl-left-margin}[Velten, B. <em>et al.</em> <a href="https://doi.org/10.1038/s41592-021-01343-9">Identifying temporal and
spatial patterns of variation from multimodal data using
MEFISTO</a>. <em>Nature Methods</em>
<strong>19</strong>, 179--186 (2022).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B161_dialogue2022 .csl-entry}
[89. ]{.csl-left-margin}[Jerby-Arnon, L. &amp; Regev, A. <a href="https://doi.org/10.1038/s41587-022-01288-0">DIALOGUE maps
multicellular programs in tissue from single-cell or spatial
transcriptomics data</a>.
<em>Nature Biotechnology</em> <strong>40</strong>, 1467--1477 (2022).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B162_tensor2024 .csl-entry}
[90. ]{.csl-left-margin}[Mitchel, J. <em>et al.</em> Coordinated, multicellular
patterns of transcriptional variation that stratify patient cohorts are
revealed by tensor decomposition. <em>Nature Biotechnology</em> (2024)
doi:<a href="https://doi.org/10.1038/s41587-024-02411-z">10.1038/s41587-024-02411-z</a>.]{.csl-right-inline}
:::</p>
<p>::: {#ref-B163_NNMF2023 .csl-entry}
[91. ]{.csl-left-margin}[Townes, F. W. &amp; Engelhardt, B. E. <a href="https://doi.org/10.1038/s41592-022-01687-w">Nonnegative
spatial factorization applied to spatial
genomics</a>. <em>Nature Methods</em>
<strong>20</strong>, 229--238 (2023).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B164_naronet2022 .csl-entry}
[92. ]{.csl-left-margin}[Jiménez-Sánchez, D. <em>et al.</em> <a href="https://doi.org/10.1016/j.media.2022.102384">NaroNet:
Discovery of tumor microenvironment elements from highly multiplexed
images</a>. <em>Medical Image
Analysis</em> <strong>78</strong>, 102384 (2022).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B165_fu2023 .csl-entry}
[93. ]{.csl-left-margin}[Fu, X., Patrick, E., Yang, J. Y. H., Feng, D.
D. &amp; Kim, J. <a href="https://doi.org/10.1016/j.compbiomed.2023.106576">Deep multimodal graph-based network for survival
prediction from highly multiplexed images and patient
variables</a>. <em>Computers
in Biology and Medicine</em> <strong>154</strong>, 106576 (2023).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B166_risom2022 .csl-entry}
[94. ]{.csl-left-margin}[Risom, T. <em>et al.</em> <a href="https://doi.org/10.1016/j.cell.2021.12.023">Transition to invasive
breast cancer is associated with progressive changes in the structure
and composition of tumor
stroma</a>. <em>Cell</em> <strong>185</strong>,
299--310.e18 (2022).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B167_s3cima2023 .csl-entry}
[95. ]{.csl-left-margin}[Babaei, S. <em>et al.</em> <a href="https://doi.org/10.1016/j.patter.2023.100829">S3-CIMA: Supervised
spatial single-cell image analysis for identifying disease-associated
cell-type compositions in
tissue</a>. <em>Patterns</em> <strong>4</strong>,
100829 (2023).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B168_wang2022 .csl-entry}
[96. ]{.csl-left-margin}[Wang, Y. <em>et al.</em> <a href="https://doi.org/10.1038/s41698-022-00285-5">Cell graph neural networks
enable the precise prediction of patient survival in gastric
cancer</a>. <em>npj Precision
Oncology</em> <strong>6</strong>, 45 (2022).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B169_perezGuide2024 .csl-entry}
[97. ]{.csl-left-margin}[Perez-Lopez, R., Ghaffari Laleh, N., Mahmood,
F. &amp; Kather, J. N. <a href="https://doi.org/10.1038/s41568-024-00694-7">A guide to artificial intelligence for cancer
researchers</a>. <em>Nature
Reviews Cancer</em> <strong>24</strong>, 427--441 (2024).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B170_review2024 .csl-entry}
[98. ]{.csl-left-margin}[Unger, M. &amp; Kather, J. N. <a href="https://doi.org/10.1186/s12920-024-01796-9">A systematic
analysis of deep learning in genomics and histopathology for precision
oncology</a>. <em>BMC Medical
Genomics</em> <strong>17</strong>, 48 (2024).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B171_hao2021 .csl-entry}
[99. ]{.csl-left-margin}[Hao, Y. <em>et al.</em> <a href="https://doi.org/10.1016/j.cell.2021.04.048">Integrated analysis of
multimodal single-cell
data</a>. <em>Cell</em> <strong>184</strong>,
3573--3587.e29 (2021).]{.csl-right-inline}
:::</p>
<p>::: {#ref-G6_scanpy_2018 .csl-entry}
[100. ]{.csl-left-margin}[Wolf, F. A., Angerer, P. &amp; Theis, F. J.
<a href="https://doi.org/10.1186/s13059-017-1382-0">SCANPY: Large-scale single-cell gene expression data
analysis</a>. <em>Genome Biology</em>
<strong>19</strong>, 15 (2018).]{.csl-right-inline}
:::</p>
<p>::: {#ref-g25_anndata .csl-entry}
[101. ]{.csl-left-margin}[Virshup, I., Rybakov, S., Theis, F. J.,
Angerer, P. &amp; Wolf, F. A. <a href="https://doi.org/10.21105/joss.04371">Anndata: Access and store annotated
datamatrices</a>. <em>Journal of Open
Source Software</em> <strong>9</strong>, 4371 (2024).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B174_giotto2021 .csl-entry}
[102. ]{.csl-left-margin}[Dries, R. <em>et al.</em> <a href="https://doi.org/10.1186/s13059-021-02286-2">Giotto: A toolbox for
integrative analysis and visualization of spatial expression
data</a>. <em>Genome Biology</em>
<strong>22</strong>, 78 (2021).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B175_spatialdata2025 .csl-entry}
[103. ]{.csl-left-margin}[Marconato, L. <em>et al.</em> <a href="https://doi.org/10.1038/s41592-024-02212-x">SpatialData: An open
and universal data framework for spatial
omics</a>. <em>Nature Methods</em>
<strong>22</strong>, 58--62 (2025).]{.csl-right-inline}
:::</p>
<p>::: {#ref-g17_napari .csl-entry}
[104. ]{.csl-left-margin}[Sofroniew, N. <em>et al.</em> Napari: A
multi-dimensional image viewer for Python. (2025)
doi:<a href="https://doi.org/10.5281/ZENODO.3555620">10.5281/ZENODO.3555620</a>.]{.csl-right-inline}
:::</p>
<p>::: {#ref-B51_museumST_2022 .csl-entry}
[105. ]{.csl-left-margin}[Moses, L. &amp; Pachter, L. <a href="https://doi.org/10.1038/s41592-022-01409-2">Museum of spatial
transcriptomics</a>. <em>Nature
Methods</em> <strong>19</strong>, 534--546 (2022).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B177_julia2023 .csl-entry}
[106. ]{.csl-left-margin}[Roesch, E. <em>et al.</em> <a href="https://doi.org/10.1038/s41592-023-01832-z">Julia for
biologists</a>. <em>Nature
Methods</em> <strong>20</strong>, 655--664 (2023).]{.csl-right-inline}
:::</p>
<p>::: {#ref-B178_scverse2023 .csl-entry}
[107. ]{.csl-left-margin}[Virshup, I. <em>et al.</em> <a href="https://doi.org/10.1038/s41587-023-01733-8">The scverse project
provides a computational ecosystem for single-cell omics data
analysis</a>. <em>Nature
Biotechnology</em> <strong>41</strong>, (2023).]{.csl-right-inline}
:::</p>
<p>::: {#ref-G15_pixie .csl-entry}
[108. ]{.csl-left-margin}[Liu, C. C. <em>et al.</em> <a href="https://doi.org/10.1038/s41467-023-40068-5">Robust phenotyping of
highly multiplexed tissue imaging data using pixel-level
clustering</a>. <em>Nature
Communications</em> <strong>14</strong>, (2023).]{.csl-right-inline}
:::
:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.sections", "toc.integrate"], "search": "../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
    
  </body>
</html>